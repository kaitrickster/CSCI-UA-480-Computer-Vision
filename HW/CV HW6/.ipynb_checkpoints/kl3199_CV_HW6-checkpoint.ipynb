{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Vision HW6\n",
    "# Author: Kai Liao\n",
    "# Trained on Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.path import Path\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EgoHands(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        folders = sorted(glob(os.path.join(self.path, \"*\")))\n",
    "        self.imgs = []\n",
    "        self.polygons = []\n",
    "        for folder in folders:\n",
    "            # Add images\n",
    "            self.imgs += sorted(glob(os.path.join(folder, \"*.jpg\")))\n",
    "            \n",
    "            # Add polygons\n",
    "            polygon_path = glob(os.path.join(folder, \"*.mat\"))[0]\n",
    "            polygon = loadmat(polygon_path)['polygons'][0]\n",
    "            for i in range(len(polygon)):\n",
    "                self.polygons.append(polygon[i])\n",
    "                \n",
    "        # TODO: use suitable transformations\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load image\n",
    "        img = np.array(Image.open(self.imgs[index]))\n",
    "\n",
    "        # Compute mask\n",
    "        polygons = self.polygons[index]\n",
    "        gt_mask = []\n",
    "        x, y = np.meshgrid(\n",
    "            np.arange(img.shape[1]), np.arange(img.shape[0]))\n",
    "        x, y = x.flatten(), y.flatten()\n",
    "        points = np.vstack((x, y)).T\n",
    "        for i, polygon in enumerate(polygons):\n",
    "            if polygon.size == 0:\n",
    "                continue\n",
    "            path = Path(polygon)\n",
    "            grid = path.contains_points(points)\n",
    "            grid = grid.reshape((*img.shape[:2]))\n",
    "            gt_mask.append(np.expand_dims(grid, axis=-1))\n",
    "        \n",
    "        try:\n",
    "            gt_mask = np.concatenate(gt_mask, axis=-1)\n",
    "            target = {}\n",
    "            boxes = []\n",
    "            for i in range(gt_mask.shape[2]):\n",
    "                pos = np.where(gt_mask[:,:,i])\n",
    "                xmin = np.min(pos[1])\n",
    "                xmax = np.max(pos[1])\n",
    "                ymin = np.min(pos[0])\n",
    "                ymax = np.max(pos[0])\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            labels = torch.ones((gt_mask.shape[2],), dtype=torch.int64)\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            target[\"boxes\"] = boxes\n",
    "            target[\"labels\"] = labels\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            return img, target\n",
    "        \n",
    "        except:\n",
    "            '''\n",
    "            return next image that has mask\n",
    "            it may happen that an image is used multiple times during training\n",
    "            but the effect is parhaps negligible given the size of dataset.\n",
    "            '''\n",
    "            return self.__getitem__(index + 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transforms as T\n",
    "import utils\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "\n",
    "# set up model\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "# define dataset: 70/30 train/val\n",
    "train_set = EgoHands('_LABELLED_SAMPLES/', get_transform(train=True))\n",
    "val_set = EgoHands('_LABELLED_SAMPLES/', get_transform(train=False))\n",
    "indices = torch.randperm(len(train_set)).tolist()\n",
    "train_size = int(len(train_set) * 0.7)\n",
    "val_set = torch.utils.data.Subset(val_set, indices[:-train_size])\n",
    "train_set = torch.utils.data.Subset(train_set, indices[-train_size:])\n",
    "\n",
    "# define dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=2, shuffle=True, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_set, batch_size=1, shuffle=False, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "\n",
    "def training():\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)\n",
    "\n",
    "    num_epochs = 1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=120)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/1680]  eta: 4:10:42  lr: 0.000010  loss: 1.1070 (1.1070)  loss_classifier: 0.8615 (0.8615)  loss_box_reg: 0.1972 (0.1972)  loss_objectness: 0.0380 (0.0380)  loss_rpn_box_reg: 0.0104 (0.0104)  time: 8.9539  data: 7.1215  max mem: 2478\n",
      "Epoch: [0]  [ 120/1680]  eta: 1:31:31  lr: 0.000609  loss: 0.3827 (0.5668)  loss_classifier: 0.1414 (0.2852)  loss_box_reg: 0.2023 (0.2162)  loss_objectness: 0.0093 (0.0450)  loss_rpn_box_reg: 0.0144 (0.0205)  time: 3.5910  data: 3.1086  max mem: 2743\n",
      "Epoch: [0]  [ 240/1680]  eta: 1:25:25  lr: 0.001209  loss: 0.2114 (0.4101)  loss_classifier: 0.1006 (0.1972)  loss_box_reg: 0.0833 (0.1609)  loss_objectness: 0.0055 (0.0317)  loss_rpn_box_reg: 0.0143 (0.0203)  time: 3.3144  data: 2.8603  max mem: 2743\n",
      "Epoch: [0]  [ 360/1680]  eta: 1:17:49  lr: 0.001808  loss: 0.1509 (0.3465)  loss_classifier: 0.0695 (0.1597)  loss_box_reg: 0.0594 (0.1331)  loss_objectness: 0.0030 (0.0323)  loss_rpn_box_reg: 0.0122 (0.0214)  time: 3.0920  data: 2.6411  max mem: 2743\n",
      "Epoch: [0]  [ 480/1680]  eta: 1:10:10  lr: 0.002408  loss: 0.1865 (0.3030)  loss_classifier: 0.0806 (0.1394)  loss_box_reg: 0.0732 (0.1178)  loss_objectness: 0.0034 (0.0259)  loss_rpn_box_reg: 0.0123 (0.0199)  time: 3.3530  data: 2.9006  max mem: 2743\n",
      "Epoch: [0]  [ 600/1680]  eta: 1:03:06  lr: 0.003007  loss: 0.1302 (0.2750)  loss_classifier: 0.0547 (0.1261)  loss_box_reg: 0.0500 (0.1070)  loss_objectness: 0.0017 (0.0223)  loss_rpn_box_reg: 0.0138 (0.0196)  time: 3.5560  data: 3.0899  max mem: 2743\n",
      "Epoch: [0]  [ 720/1680]  eta: 0:55:41  lr: 0.003606  loss: 0.1276 (0.2554)  loss_classifier: 0.0575 (0.1176)  loss_box_reg: 0.0428 (0.0992)  loss_objectness: 0.0048 (0.0197)  loss_rpn_box_reg: 0.0108 (0.0188)  time: 3.2256  data: 2.7677  max mem: 2743\n",
      "Epoch: [0]  [ 840/1680]  eta: 0:49:01  lr: 0.004206  loss: 0.1332 (0.2416)  loss_classifier: 0.0625 (0.1113)  loss_box_reg: 0.0451 (0.0935)  loss_objectness: 0.0037 (0.0181)  loss_rpn_box_reg: 0.0137 (0.0186)  time: 3.9348  data: 3.4667  max mem: 2743\n",
      "Epoch: [0]  [ 960/1680]  eta: 0:41:55  lr: 0.004805  loss: 0.1598 (0.2315)  loss_classifier: 0.0777 (0.1068)  loss_box_reg: 0.0556 (0.0897)  loss_objectness: 0.0045 (0.0167)  loss_rpn_box_reg: 0.0111 (0.0183)  time: 3.2951  data: 2.8676  max mem: 2743\n",
      "Epoch: [0]  [1080/1680]  eta: 0:34:48  lr: 0.005000  loss: 0.1363 (0.2228)  loss_classifier: 0.0684 (0.1027)  loss_box_reg: 0.0492 (0.0859)  loss_objectness: 0.0025 (0.0160)  loss_rpn_box_reg: 0.0096 (0.0181)  time: 2.9920  data: 2.5137  max mem: 2743\n",
      "Epoch: [0]  [1200/1680]  eta: 0:27:54  lr: 0.005000  loss: 0.1513 (0.2165)  loss_classifier: 0.0658 (0.0994)  loss_box_reg: 0.0688 (0.0831)  loss_objectness: 0.0034 (0.0159)  loss_rpn_box_reg: 0.0116 (0.0180)  time: 3.3484  data: 2.8866  max mem: 2743\n",
      "Epoch: [0]  [1320/1680]  eta: 0:20:52  lr: 0.005000  loss: 0.1256 (0.2099)  loss_classifier: 0.0549 (0.0965)  loss_box_reg: 0.0452 (0.0806)  loss_objectness: 0.0014 (0.0149)  loss_rpn_box_reg: 0.0118 (0.0178)  time: 3.1216  data: 2.6693  max mem: 2743\n",
      "Epoch: [0]  [1440/1680]  eta: 0:13:57  lr: 0.005000  loss: 0.1028 (0.2049)  loss_classifier: 0.0493 (0.0939)  loss_box_reg: 0.0373 (0.0782)  loss_objectness: 0.0049 (0.0148)  loss_rpn_box_reg: 0.0115 (0.0180)  time: 3.5608  data: 3.1359  max mem: 2743\n",
      "Epoch: [0]  [1560/1680]  eta: 0:06:59  lr: 0.005000  loss: 0.1247 (0.1994)  loss_classifier: 0.0597 (0.0915)  loss_box_reg: 0.0495 (0.0761)  loss_objectness: 0.0035 (0.0141)  loss_rpn_box_reg: 0.0100 (0.0177)  time: 2.9980  data: 2.5193  max mem: 2743\n",
      "Epoch: [0]  [1679/1680]  eta: 0:00:03  lr: 0.005000  loss: 0.1169 (0.1956)  loss_classifier: 0.0474 (0.0897)  loss_box_reg: 0.0406 (0.0746)  loss_objectness: 0.0025 (0.0136)  loss_rpn_box_reg: 0.0109 (0.0177)  time: 2.5428  data: 2.1067  max mem: 2743\n",
      "Epoch: [0] Total time: 1:37:24 (3.4791 s / it)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "model.eval()\n",
    "sample_inds = np.random.randint(low=0, high=len(val_set) - 1, size=5)\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ind in sample_inds:\n",
    "        predictions.append(model([val_set[ind][0].to(device)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample inference on the 1086 th image in the validation set\n",
      "[{'boxes': tensor([[640.1021, 618.8013, 898.8427, 718.0145],\n",
      "        [624.5226, 219.9917, 822.4734, 431.0540],\n",
      "        [304.4763, 173.6108, 502.3412, 416.6602],\n",
      "        [291.0628, 690.9357, 414.8874, 717.5993],\n",
      "        [630.2924, 681.4257, 716.7034, 718.1188]], device='cuda:0'), 'labels': tensor([1, 1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.9997, 0.9989, 0.9987, 0.9949, 0.0725], device='cuda:0')}]\n",
      "tensor([[304., 698., 414., 718.],\n",
      "        [648., 624., 894., 718.],\n",
      "        [632., 240., 803., 423.],\n",
      "        [325., 217., 492., 411.]])\n"
     ]
    }
   ],
   "source": [
    "# sample prediction\n",
    "print(\"sample inference on the\", sample_inds[3], \"th image in the validation set\")\n",
    "print(predictions[3])\n",
    "print(val_set[sample_inds[3]][1]['boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model, \"./model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
