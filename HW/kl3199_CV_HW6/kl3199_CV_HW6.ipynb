{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Vision HW6\n",
    "# Author: Kai Liao\n",
    "# Trained on Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.path import Path\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EgoHands(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        folders = sorted(glob(os.path.join(self.path, \"*\")))\n",
    "        self.imgs = []\n",
    "        self.polygons = []\n",
    "        for folder in folders:\n",
    "            # Add images\n",
    "            self.imgs += sorted(glob(os.path.join(folder, \"*.jpg\")))\n",
    "            \n",
    "            # Add polygons\n",
    "            polygon_path = glob(os.path.join(folder, \"*.mat\"))[0]\n",
    "            polygon = loadmat(polygon_path)['polygons'][0]\n",
    "            for i in range(len(polygon)):\n",
    "                self.polygons.append(polygon[i])\n",
    "                \n",
    "        # TODO: use suitable transformations\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load image\n",
    "        img = np.array(Image.open(self.imgs[index]))\n",
    "\n",
    "        # Compute mask\n",
    "        polygons = self.polygons[index]\n",
    "        gt_mask = []\n",
    "        x, y = np.meshgrid(\n",
    "            np.arange(img.shape[1]), np.arange(img.shape[0]))\n",
    "        x, y = x.flatten(), y.flatten()\n",
    "        points = np.vstack((x, y)).T\n",
    "        for i, polygon in enumerate(polygons):\n",
    "            if polygon.size == 0:\n",
    "                continue\n",
    "            path = Path(polygon)\n",
    "            grid = path.contains_points(points)\n",
    "            grid = grid.reshape((*img.shape[:2]))\n",
    "            gt_mask.append(np.expand_dims(grid, axis=-1))\n",
    "        \n",
    "        try:\n",
    "            gt_mask = np.concatenate(gt_mask, axis=-1)\n",
    "            target = {}\n",
    "            boxes = []\n",
    "            for i in range(gt_mask.shape[2]):\n",
    "                pos = np.where(gt_mask[:,:,i])\n",
    "                xmin = np.min(pos[1])\n",
    "                xmax = np.max(pos[1])\n",
    "                ymin = np.min(pos[0])\n",
    "                ymax = np.max(pos[0])\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "            labels = torch.ones((gt_mask.shape[2],), dtype=torch.int64)\n",
    "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            target[\"boxes\"] = boxes\n",
    "            target[\"labels\"] = labels\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            return img, target\n",
    "        \n",
    "        except:\n",
    "            '''\n",
    "            return next image that has mask\n",
    "            it may happen that an image is used multiple times during training\n",
    "            but the effect is parhaps negligible given the size of dataset.\n",
    "            '''\n",
    "            return self.__getitem__(index + 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transforms as T\n",
    "import utils\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "\n",
    "# set up model\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "# define dataset: 70/30 train/val\n",
    "train_set = EgoHands('_LABELLED_SAMPLES/', get_transform(train=True))\n",
    "val_set = EgoHands('_LABELLED_SAMPLES/', get_transform(train=False))\n",
    "indices = torch.randperm(len(train_set)).tolist()\n",
    "train_size = int(len(train_set) * 0.7)\n",
    "val_set = torch.utils.data.Subset(val_set, indices[:-train_size])\n",
    "train_set = torch.utils.data.Subset(train_set, indices[-train_size:])\n",
    "\n",
    "# define dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=2, shuffle=True, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_set, batch_size=1, shuffle=False, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "\n",
    "def training():\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)\n",
    "\n",
    "    num_epochs = 1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=120)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/1680]  eta: 12:44:04  lr: 0.000010  loss: 1.4050 (1.4050)  loss_classifier: 0.8627 (0.8627)  loss_box_reg: 0.2130 (0.2130)  loss_objectness: 0.2278 (0.2278)  loss_rpn_box_reg: 0.1014 (0.1014)  time: 27.2886  data: 25.8937  max mem: 2478\n",
      "Epoch: [0]  [ 120/1680]  eta: 1:36:20  lr: 0.000609  loss: 0.3071 (0.5678)  loss_classifier: 0.1325 (0.2856)  loss_box_reg: 0.1612 (0.2091)  loss_objectness: 0.0128 (0.0497)  loss_rpn_box_reg: 0.0151 (0.0234)  time: 3.8936  data: 3.4316  max mem: 2745\n",
      "Epoch: [0]  [ 240/1680]  eta: 1:24:28  lr: 0.001209  loss: 0.1665 (0.3933)  loss_classifier: 0.0692 (0.1893)  loss_box_reg: 0.0781 (0.1520)  loss_objectness: 0.0017 (0.0317)  loss_rpn_box_reg: 0.0140 (0.0203)  time: 3.2510  data: 2.7759  max mem: 2745\n",
      "Epoch: [0]  [ 360/1680]  eta: 1:16:34  lr: 0.001808  loss: 0.1254 (0.3219)  loss_classifier: 0.0587 (0.1535)  loss_box_reg: 0.0520 (0.1256)  loss_objectness: 0.0016 (0.0242)  loss_rpn_box_reg: 0.0111 (0.0186)  time: 3.4863  data: 3.0436  max mem: 2745\n",
      "Epoch: [0]  [ 480/1680]  eta: 1:10:21  lr: 0.002408  loss: 0.1373 (0.2890)  loss_classifier: 0.0653 (0.1350)  loss_box_reg: 0.0476 (0.1123)  loss_objectness: 0.0033 (0.0217)  loss_rpn_box_reg: 0.0139 (0.0200)  time: 3.5513  data: 3.0871  max mem: 2745\n",
      "Epoch: [0]  [ 600/1680]  eta: 1:04:08  lr: 0.003007  loss: 0.1722 (0.2624)  loss_classifier: 0.0780 (0.1232)  loss_box_reg: 0.0683 (0.1017)  loss_objectness: 0.0015 (0.0186)  loss_rpn_box_reg: 0.0140 (0.0188)  time: 3.0444  data: 2.5709  max mem: 2745\n",
      "Epoch: [0]  [ 720/1680]  eta: 0:57:01  lr: 0.003606  loss: 0.1812 (0.2470)  loss_classifier: 0.0850 (0.1159)  loss_box_reg: 0.0788 (0.0952)  loss_objectness: 0.0021 (0.0170)  loss_rpn_box_reg: 0.0138 (0.0189)  time: 3.0865  data: 2.6316  max mem: 2745\n",
      "Epoch: [0]  [ 840/1680]  eta: 0:49:46  lr: 0.004206  loss: 0.1226 (0.2367)  loss_classifier: 0.0702 (0.1105)  loss_box_reg: 0.0439 (0.0904)  loss_objectness: 0.0034 (0.0165)  loss_rpn_box_reg: 0.0112 (0.0192)  time: 3.2469  data: 2.8047  max mem: 2745\n",
      "Epoch: [0]  [ 960/1680]  eta: 0:42:30  lr: 0.004805  loss: 0.1542 (0.2274)  loss_classifier: 0.0770 (0.1059)  loss_box_reg: 0.0532 (0.0864)  loss_objectness: 0.0037 (0.0160)  loss_rpn_box_reg: 0.0128 (0.0191)  time: 2.8446  data: 2.3908  max mem: 2745\n",
      "Epoch: [0]  [1080/1680]  eta: 0:35:29  lr: 0.005000  loss: 0.1416 (0.2197)  loss_classifier: 0.0688 (0.1025)  loss_box_reg: 0.0468 (0.0834)  loss_objectness: 0.0049 (0.0153)  loss_rpn_box_reg: 0.0114 (0.0185)  time: 3.4021  data: 2.9531  max mem: 2745\n",
      "Epoch: [0]  [1200/1680]  eta: 0:28:27  lr: 0.005000  loss: 0.1381 (0.2136)  loss_classifier: 0.0635 (0.0998)  loss_box_reg: 0.0432 (0.0809)  loss_objectness: 0.0049 (0.0146)  loss_rpn_box_reg: 0.0105 (0.0183)  time: 3.9790  data: 3.5241  max mem: 2745\n",
      "Epoch: [0]  [1320/1680]  eta: 0:21:14  lr: 0.005000  loss: 0.1282 (0.2073)  loss_classifier: 0.0535 (0.0968)  loss_box_reg: 0.0575 (0.0787)  loss_objectness: 0.0015 (0.0137)  loss_rpn_box_reg: 0.0102 (0.0180)  time: 3.4843  data: 3.0340  max mem: 2745\n",
      "Epoch: [0]  [1440/1680]  eta: 0:14:07  lr: 0.005000  loss: 0.1116 (0.2025)  loss_classifier: 0.0526 (0.0945)  loss_box_reg: 0.0405 (0.0768)  loss_objectness: 0.0065 (0.0132)  loss_rpn_box_reg: 0.0105 (0.0179)  time: 4.2624  data: 3.7940  max mem: 2745\n",
      "Epoch: [0]  [1560/1680]  eta: 0:07:04  lr: 0.005000  loss: 0.1387 (0.1977)  loss_classifier: 0.0691 (0.0921)  loss_box_reg: 0.0412 (0.0748)  loss_objectness: 0.0090 (0.0130)  loss_rpn_box_reg: 0.0107 (0.0178)  time: 3.5508  data: 3.1145  max mem: 2745\n",
      "Epoch: [0]  [1679/1680]  eta: 0:00:03  lr: 0.005000  loss: 0.1229 (0.1931)  loss_classifier: 0.0584 (0.0898)  loss_box_reg: 0.0415 (0.0730)  loss_objectness: 0.0014 (0.0128)  loss_rpn_box_reg: 0.0107 (0.0175)  time: 2.5176  data: 2.1078  max mem: 2745\n",
      "Epoch: [0] Total time: 1:38:22 (3.5133 s / it)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "model.eval()\n",
    "sample_inds = np.random.randint(low=0, high=len(val_set) - 1, size=5)\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ind in sample_inds:\n",
    "        predictions.append(model([val_set[ind][0].to(device)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, Image\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    x = val_set[sample_inds[i]][0]\n",
    "    img = transforms.ToPILImage()(x).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for coordinates in predictions[i][0][\"boxes\"].tolist():\n",
    "        draw.rectangle(coordinates, outline=\"red\")\n",
    "    name = str(i)\n",
    "    name += \".png\"\n",
    "    img.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(model, \"./model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
