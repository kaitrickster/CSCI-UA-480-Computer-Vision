{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_CQks_LJ_v4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "from glob import glob\n",
    "\n",
    "# Mingxing Tan, Quoc V. Le, EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML 2019\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFUvX2EEJ_v9"
   },
   "outputs": [],
   "source": [
    "class GTSRBTrain(Dataset):\n",
    "    def __init__(self):\n",
    "        self.path = \"GTSRB/Final_Training/Images\"\n",
    "        self.folder_paths = sorted(glob(\"{}/*/\".format(self.path)))\n",
    "        self.class_ind = 0\n",
    "        \n",
    "        self.img_transforms = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.imgs = []\n",
    "        self.lbls = []\n",
    "        \n",
    "        for folder_path in self.folder_paths:\n",
    "            image_paths = sorted(glob(\"{}/*\".format(folder_path)))\n",
    "            # remove last csv file in the folder\n",
    "            image_paths.pop()\n",
    "            self.imgs += image_paths\n",
    "            self.lbls += [self.class_ind] * len(image_paths)\n",
    "            self.class_ind += 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.imgs[index]).convert(\"RGB\")\n",
    "        img = self.img_transforms(img)\n",
    "        lbl = self.lbls[index]\n",
    "        return img, lbl\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LemlM1WfJ_wF"
   },
   "outputs": [],
   "source": [
    "class GTSRBGeneric(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.imgs = []\n",
    "        self.lbls = labels\n",
    "        \n",
    "        for filename in image_paths:\n",
    "            img = Image.open(filename).convert(\"RGB\")\n",
    "            self.imgs.append(img)\n",
    "        \n",
    "        self.img_transforms = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.img_transforms(self.imgs[index])\n",
    "        lbl = self.lbls[index]\n",
    "        return img, lbl\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8owU7HCJ_wI"
   },
   "outputs": [],
   "source": [
    "# Define data augmentation\n",
    "grayscale_image = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "rotate_image = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "jitter_image = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ColorJitter(contrast=0.3, saturation=0.3, hue=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TaXUBoLIJ_wK",
    "outputId": "91bfbc86-3e93-4140-ebdf-18e335c38d24",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31367\n",
      "7842\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set = GTSRBTrain()\n",
    "\n",
    "# stratified sampling: use 20% of images in each class as the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train_set.imgs, train_set.lbls, test_size=0.2, stratify=train_set.lbls, random_state=0)\n",
    "\n",
    "train_set = GTSRBGeneric(X_train, y_train, default_transform)\n",
    "val_set = GTSRBGeneric(X_val, y_val, default_transform)\n",
    "print(len(train_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rg6wtLnGJ_wO",
    "outputId": "d3b0e5a7-a182-4f9e-b064-54ae151dee88",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125468\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "# augment training set\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "   torch.utils.data.ConcatDataset(\n",
    "       [train_set, GTSRBGeneric(X_train, y_train, grayscale_image),\n",
    "        GTSRBGeneric(X_train, y_train, rotate_image), GTSRBGeneric(X_train, y_train, jitter_image)]\n",
    "   ), batch_size=16, shuffle=True, )\n",
    "\n",
    "print(len(train_loader.dataset))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-vh3BuSJ_wR"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # model with randomly intialized weights\n",
    "        self.effNet = EfficientNet.from_name('efficientnet-b2')\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(1000, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 43)\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.effNet(x)\n",
    "        x = self.MLP(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Ss68nc4J_wW",
    "outputId": "2751f17a-db68-458b-aee0-82ae4fe9e53b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "model = Net()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-q1iwvG5J_wd"
   },
   "outputs": [],
   "source": [
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "best_val_acc = 0.0\n",
    "PATH = 'model.pth'\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    for i, (imgs, lbls) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs.to(device))\n",
    "        loss = criterion(outputs, lbls.to(device))\n",
    "        pred = outputs.argmax(dim=1, keepdim=True).cpu()\n",
    "        train_correct += pred.eq(lbls.view_as(pred)).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss_history.append(loss.item())\n",
    "    train_acc_history.append(train_correct / len(train_loader.dataset))\n",
    "    \n",
    "    print(epoch)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    for imgs, lbls in val_loader:\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        outputs = model(imgs)\n",
    "        val_loss += criterion(outputs, lbls).item()\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "        val_correct += pred.eq(lbls.view_as(pred)).sum().item()\n",
    "\n",
    "    val_acc = val_correct / len(val_loader.dataset)\n",
    "    val_loss_history.append(val_loss / len(val_loader.dataset))  \n",
    "    val_acc_history.append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZrK5j8rJ_wg"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = np.arange(len(train_loss_history))\n",
    "plt.plot(x1, train_loss_history)\n",
    "plt.plot(x1, val_loss_history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EY20v2HWJ_wl"
   },
   "outputs": [],
   "source": [
    "x2 = np.arange(len(train_acc_history))\n",
    "plt.plot(x2, train_acc_history)\n",
    "plt.plot(x2, val_acc_history)\n",
    "plt.title(\"\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CV_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
